<table>
  <tr>
    <td style="border:none">
      <a href="#cont"><h3>Contact</h3></a>
    </td>
    <td style="border:none">
      <a href="#cv"><h3>CV</h3></a>
    </td>
    <td style="border:none">
      <a href="#teach"><h3>Teaching</h3></a>
    </td>
    <td style="border:none">
      <a href="#publ"><h3>Publications</h3></a>
    </td>
    <td style="border:none">
      <a href="#code"><h3>Code</h3></a>
    </td>
  </tr>
</table>

---

<br/>

<table>
  <tr>
    <td style="border:none;">
      <b>Welcome to my page!</b> <br><br>
      I am an assistant professor working on mathematics of data science and machine learning. My former research has been focused on compressed sensing and the influence of quantization on signal reconstruction.
      I am currently interested in 
      <br><br>
      <ul>
        <li>covariance estimation</li> 
        <li>approximation properties of neural networks</li> 
        <li>the implicit bias of gradient descent in network training</li> 
        <li>recovery of multi-structured signals.</li> 
      </ul>
      Moreover, I theoretically investigate the influence of coarse quantization in all of these areas.
      <br><br>
      I am a <a href="https://zuseschoolrelai.de/">relAI Fellow</a> and an <a href="https://mcml.ai/">MCML Associate</a>. 
    </td>
    <td style="float: right;width: 60%;border:none">
      <img src="Photo2_JohannesMaly.jpg">
    </td>
  </tr>
</table>

<br>

## Contact {#cont}

Current address: Bavarian AI Chair for Mathematical Foundations of Artificial Intelligence, LMU Munich, Akademiestr. 7, D-80799 München

E-mail: maly(at)math(dot)lmu(dot)de

<br>

## Short CV {#cv}

- 10/2022 - now: Assistant professor for "Mathematical Data Science" at the chair of *[Bavarian AI Chair for Mathematical Foundations of Artificial Intelligence](https://www.mathematik.uni-muenchen.de/forschung/arbeitsgruppen/ki/index.html)* at LMU, Munich
- 11/2020 - 09/2022: PostDoc (akademischer Rat auf Zeit) at the *[Department of Scientific Computing](https://www.ku.de/en/mgf/mathematics/scientific-computing)* at Catholic University of Eichstaett-Ingolstadt
- 02/2019 - 10/2020: PostDoc at the *[Chair for Mathematics of Data Processing](https://www.mathc.rwth-aachen.de/home/home)* at RWTH Aachen University
- 01/2016 - 01/2019: PhD at the *[Chair for Applied and Numerical Analysis and Optimization and Data Analysis](https://www-m15.ma.tum.de/Allgemeines/WebHome)* at TUM, Munich, under supervision of Prof. Massimo Fornasier
- 10/2013 - 09/2015: M.Sc. in mathematics at TUM, Munich
- 05/2011 - 09/2013: B.Sc. in mathematics at TUM, Munich

<br>

## Teaching {#teach}

### LMU

- 04/2025 - 09/2025: ["Mathematische Einführung in Data Science"](https://www.ai.math.uni-muenchen.de/teaching/sose2025/meds/index.html) (Lecture)
- 04/2024 - 09/2024: ["Convex Optimization"](https://www.ai.math.uni-muenchen.de/teaching/sose2024/convex_optimization/index.html) (Lecture)
- 10/2023 - 03/2024: ["High-dimensional Probability"](https://www.ai.math.uni-muenchen.de/teaching/wise23_24/high-dimensional-probability/index.html) (Lecture)
- 04/2023 - 09/2023: ["Convex Optimization for Data Science"](https://www.ai.math.uni-muenchen.de/teaching/sose2023/convex_optimization/index.html) (Lecture)
- 10/2022 - 03/2023: ["Mathematical Signal and Image Processing"](https://www.ai.math.uni-muenchen.de/teaching/wise22_23/math-image-processing/index.html) (Lecture)

### Catholic University of Eichstaett/Ingolstadt

- 04/2022 - 09/2022: "Introduction to Scientific Computing" (Lecture+Exercises)
- 10/2021 - 03/2022: "Mathematics for Economics" (Lecture)
- 04/2021 - 09/2021: "Introduction to Scientific Computing" (Lecture+Exercises)
- 11/2020 - 03/2021: "Introduction to Numerical Analysis" (Lecture+Exercises)

### RWTH Aachen University

- 04/2020 - 09/2020: Teaching assistant for "Optimization"
- 10/2019 - 03/2020: Teaching assistant for "Repetitorium - Higher Mathematics II"
- 04/2019 - 09/2019: Teaching assistant for "Higher Mathematics II"

### Technical University of Munich

- 04/2018 - 09/2018: Teaching assistant for "Foundations of Data Analysis"

<br>

## Publications {#publ}

### Preprints

- V. Fojtik, M. Matveev, H.--H. Chou, G. Kutyniok, and J. Maly: *"Conflicting Biases at the Edge of Stability: Norm versus Sharpness Regularization"*, 2025, *[arXiv preprint](https://arxiv.org/abs/2505.21423)*
- S. Dirksen, W. Li, and J. Maly: *"Subspace and DOA estimation under coarse quantization"*, 2025, *[arXiv preprint](https://arxiv.org/abs/2502.17037)*
- H.--H. Chou, J. Maly, and D. Stöger: *"How to induce regularization in generalized linear models: A guide to reparametrizing gradient flow"*, 2023, *[arXiv preprint](https://arxiv.org/abs/2308.04921)*

### Journal publications

#### 2024

- S. Dirksen and J. Maly: *["Tuning-free one-bit covariance estimation using data-driven dithering"](https://ieeexplore.ieee.org/document/10415223)*, 2024, *IEEE Transactions on Information Theory*, *([arXiv](https://arxiv.org/abs/2307.12613))*
- H.--H. Chou, C. Gieshoff, J. Maly, and H. Rauhut: *["Gradient Descent for Deep Matrix Factorization: Dynamics and Implicit Bias towards Low Rank"](https://www.sciencedirect.com/science/article/abs/pii/S1063520323000829)*, 2024, *Applied and Computational Harmonic Analysis*, *([arXiv](https://arxiv.org/abs/2011.13772))*
- T. Yang, J. Maly, S. Dirksen, and G. Caire: *["Plug-in Channel Estimation with Dithered Quantized Signals in Spatially Non-Stationary Massive MIMO Systems"](https://ieeexplore.ieee.org/document/10258362)*, 2024, *IEEE Transactions on Communications*, *([arXiv](https://arxiv.org/abs/2301.04641))*

#### 2023

- J. Maly: *["Robust Sensing of Low-Rank Matrices with Non-Orthogonal Sparse Decomposition"](https://www.sciencedirect.com/science/article/abs/pii/S1063520323000507)*, 2023, *Applied and Computational Harmonic Analysis*, *([arXiv](https://arxiv.org/abs/2103.05523))*
- J. Maly and R. Saab: *["A simple approach for quantizing neural networks"](https://www.sciencedirect.com/science/article/abs/pii/S1063520323000337)*, 2023, *Applied and Computational Harmonic Analysis*, *([arXiv](https://arxiv.org/abs/2209.03487))*
- H.--H. Chou, J. Maly, and H. Rauhut: *["More is Less: Inducing Sparsity via Overparameterization"](https://academic.oup.com/imaiai/article-abstract/12/3/iaad012/7133662?redirectedFrom=fulltext)*, 2023, *Information and Inference: A Journal of the IMA*, *([arXiv](https://arxiv.org/abs/2112.11027))*

#### 2022

- S. Dirksen, J. Maly, and H. Rauhut: *["Covariance estimation under one-bit quantization"](https://projecteuclid.org/journals/annals-of-statistics/volume-50/issue-6/Covariance-estimation-under-one-bit-quantization/10.1214/22-AOS2239.short)*, 2022, *Annals of Statistics*, *([arXiv](https://arxiv.org/abs/2104.01280))*
- A. Caragea, D. G. Lee, J. Maly, G. Pfander, and F. Voigtlaender: *["Quantitative approximation results for complex-valued neural networks"](https://epubs.siam.org/doi/abs/10.1137/21M1429540)*, 2022, *SIAM Journal on Mathematics of Data Science (SIMODS)*, *([arXiv](https://arxiv.org/abs/2102.13092))*

#### 2021

- F. Boßmann, S. Krause-Solberg, J. Maly, and N. Sissouno: *["Structural Sparsity in Multiple Measurements"](https://ieeexplore.ieee.org/document/9661310)*, 2021, *IEEE Transactions on Signal Processing*, *([arXiv](https://arxiv.org/abs/2103.01908))*
- Z. Kereta, J. Maly, and V. Naumova: *["Computational approaches to non-convex, sparsity-inducing multi-penalty regularization"](https://iopscience.iop.org/article/10.1088/1361-6420/abdd46)*, 2021, *Inverse Problems*, *([arXiv](https://arxiv.org/abs/1908.02503))*
- M. Iwen, F. Krahmer, S. Krause-Solberg, and J. Maly: *["On Recovery Guarantees for One-Bit Compressed Sensing on Manifolds"](https://link.springer.com/article/10.1007/s00454-020-00267-z)*, 2021, *Discrete and Computational Geometry*, *([arXiv](https://arxiv.org/abs/1807.06490))*
- H. C. Jung, J. Maly, L. Palzer, and A. Stollenwerk: *["Quantized Compressed Sensing by Rectified Linear Units"](https://ieeexplore.ieee.org/document/9393953)*, 2021, *IEEE Transactions on Information Theory*, *([arXiv](https://arxiv.org/abs/1911.07816))*

#### 2020

- M. Fornasier, J. Maly and V. Naumova: *["Robust Recovery of Low-Rank Matrices with Non-Orthogonal Sparse Decomposition from Incomplete Measurements"](https://authors.elsevier.com/a/1btjM_2C8gesk-)*, 2020, *Applied Mathematics and Computation*, *([arXiv](https://arxiv.org/abs/1801.06240))*

#### 2019

- J. Maly and L. Palzer: *["Analysis of Hard-Thresholding for Distributed Compressed Sensing with One-Bit Measurements"](https://academic.oup.com/imaiai/advance-article-abstract/doi/10.1093/imaiai/iaz004/5424056?redirectedFrom=PDF)*, 2019, *Information and Inference: A Journal of the IMA*, *([arXiv](https://arxiv.org/abs/1805.03486))*

### Conference publications

#### 2025

- H.--H. Chou, J. Maly, C. Mayrink Verdun, B. Freitas Paulo da Costa, and H. Mirandola: *"Get rid of your constraints and reparametrize: A study in NNLS and implicit bias"*, 2025, *to appear in International Conference on Artificial Intelligence and Statistics*, *([arXiv](https://arxiv.org/abs/2207.08437))*

#### 2023

- C. Kümmerle and J. Maly: *["Recovering Simultaneously Structured Data via Non-Convex Iteratively Reweighted Least Squares"](https://proceedings.neurips.cc/paper_files/paper/2023/hash/e33a4d41305fb34316df6f3fa8a0e58c-Abstract-Conference.html)*, 2023, *NeurIPS 2023*, *([arXiv](https://arxiv.org/abs/2306.04961))*

#### 2021

- S. Dirksen, J. Maly, and H. Rauhut: *["Covariance estimation under one-bit quantization"](https://onlinelibrary.wiley.com/doi/10.1002/pamm.202100063)*, 2021, *Proceedings in Applied Mathematics and Mechanics --- PAMM*
- H. C. Jung, J. Maly, L. Palzer, and A. Stollenwerk: *["Quantized Compressed Sensing by Rectified Linear Units"](https://onlinelibrary.wiley.com/doi/10.1002/pamm.202000015)*, 2021, *Proceedings in Applied Mathematics and Mechanics --- PAMM*

#### 2020

- A. Guth, C. Culotta-López, J. Maly, H. Rauhut, and D. Heberling: *["Polyhedral Sampling Structures for Phaseless Spherical Near-Field Antenna Measurements"](https://www.researchgate.net/publication/346020497_Polyhedral_Sampling_Structures_for_Phaseless_Spherical_Near-Field_Antenna_Measurements)*, 2020, *42nd Antenna Measurement Techniques Association Symposium (AMTA)*
- H. C. Jung, J. Maly, L. Palzer, and A. Stollenwerk: *"Quantized Compressed Sensing by Rectified Linear Units"*, 2020, *iTWIST'20*

#### 2019

- S. Dirksen, M. Iwen, S. Krause-Solberg, and J. Maly: *["Robust One-bit Compressed Sensing With Manifold Data"](https://sampta2019.sciencesconf.org/267528/document)*, 2019, *International Conference on Sampling Theory and Applications (SampTA)*
- H. C. Jung, J. Maly, L. Palzer, and A. Stollenwerk: *"One-Bit Compressed Sensing by Convex Relaxation of the Hamming Distance"*, 2019, *SPARS workshop*
- Z. Kereta, J. Maly, and V. Naumova: *Linear convergence and support recovery for non-convex multi-penalty regularisation*, 2019, *SPARS workshop*

#### 2017

- M. Fornasier, J. Maly and V. Naumova: *["Robust Recovery of Low-Rank Matrices using Multi-Penalty Regularization"](http://opt-ml.org/papers.html)*, 2017, *NIPS workshop Optimization for Machine Learning*
- S. Krause-Solberg and J. Maly: *["A tractable approach for one-bit Compressed Sensing on manifolds"](https://ieeexplore.ieee.org/document/8024465)*, 2017, *International Conference on Sampling Theory and Applications (SampTA)*

### Book chapters

- J. Maly, T. Yang, S. Dirksen, H. Rauhut, and G. Caire: *"New challenges in covariance estimation: multiple structures and coarse quantization" in [Compressed Sensing in Information Processing](https://link.springer.com/book/10.1007/978-3-031-09745-4)*, 2021, Springer, *([arXiv](https://arxiv.org/abs/2106.06190))*

### Theses

- J. Maly: *["Recovery Algorithms for Quantized Compressed Sensing"](https://mediatum.ub.tum.de/1471689)*, 2019, Phd thesis
- J. Maly: *"Weighted Energy-Dissipation Approximation for an Optimal Control Problem"*, 2015, Master's thesis

<br>

## Code

- [Supplementary material](AdaptiveDither_CODE.zip) for *"Tuning-free one-bit covariance estimation using data-driven dithering"*
- [Supplementary material](S3-PCA-Toolbox.zip) for *"Robust Sensing of Low-Rank Matrices with Non-Orthogonal Sparse Decomposition"*
- [Supplementary material](ATLAS_Toolbox.zip) for *"Robust Recovery of Low-Rank Matrices with Non-Orthogonal Sparse Decomposition from Incomplete Measurements"*
- [Supplementary material](OMSpaperCODE.zip) for *"On Recovery Guarantees for One-Bit Compressed Sensing on Manifolds"*

<!--
<!-- You can use the [editor on GitHub](https://github.com/johannes-maly/johannes-maly.github.io/edit/master/README.md) to maintain and preview the content for your website in Markdown files. -->

<!-- Whenever you commit to this repository, GitHub Pages will run [Jekyll](https://jekyllrb.com/) to rebuild the pages in your site, from the content in your Markdown files. -->

<!-- ### Markdown-->

<!-- Markdown is a lightweight and easy-to-use syntax for styling your writing. It includes conventions for

<!-- ```markdown
<!-- Syntax highlighted code block

<!-- # Header 1
<!-- ## Header 2
<!-- ### Header 3

<!-- - Bulleted
<!-- - List

<!-- 1. Numbered
<!-- 2. List

<!-- **Bold** and _Italic_ and `Code` text

<!-- [Link](url) and ![Image](src)
<!-- ```

<!-- For more details see [GitHub Flavored Markdown](https://guides.github.com/features/mastering-markdown/).

<!-- ### Jekyll Themes

<!-- Your Pages site will use the layout and styles from the Jekyll theme you have selected in your [repository settings](https://github.com/johannes-maly/johannes-maly.github.io/settings). The name of this theme is saved in the Jekyll `_config.yml` configuration file.

<!-- ### Support or Contact

<!-- Having trouble with Pages? Check out our [documentation](https://help.github.com/categories/github-pages-basics/) or [contact support](https://github.com/contact) and we’ll help you sort it out.  
-->
